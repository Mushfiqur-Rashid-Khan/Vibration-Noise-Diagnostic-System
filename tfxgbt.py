# -*- coding: utf-8 -*-
"""TFXGBT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B3LaKT3wjiEez_2uHGZjj-Pr-NXjEgPN

**Signal Drift**
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
X = df.drop(columns=["Signal Drift"])
y = df["Signal Drift"]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Signal Drift'],
            yticklabels=['No', 'Signal Drift'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

df.head()

print("âœ… Unique labels in dataset:", df.iloc[:, -2].unique())

"""**Gas Leakage**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
X = df.iloc[:, :-2]
y = df.iloc[:, -2]


# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Gas Leakage'],
            yticklabels=['No', 'Gas Leakage'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

"""**Noise Levels**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
X = df.iloc[:, :-3]
y = df.iloc[:, -3]


# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['Low', 'High'],
            yticklabels=['Low', 'High'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

"""Radiation Induced Degradation"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
# 2. Feature & target separation
X = df.iloc[:, :-4]
y = df.iloc[:, -4]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Yes'],
            yticklabels=['No', 'Yes'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

"""**Thermal Drift**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
# 2. Feature & target separation
X = df.iloc[:, :-5]
y = df.iloc[:, -5]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Yes'],
            yticklabels=['No', 'Yes'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

"""**Sensor Aging / Degradation**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
# 2. Feature & target separation
X = df.iloc[:, :-6]
y = df.iloc[:, -6]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Yes'],
            yticklabels=['No', 'Yes'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

"""**Offset Bias**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
# 2. Feature & target separation
X = df.iloc[:, :-7]
y = df.iloc[:, -7]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Yes'],
            yticklabels=['No', 'Yes'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()

"""**Wiring Reversal**"""

import pandas as pd
import numpy as np
from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
from sklearn.model_selection import train_test_split
import seaborn as sns
import tensorflow as tf
import matplotlib.pyplot as plt
import tensorflow_decision_forests as tfdf
from imblearn.over_sampling import SMOTE
from sklearn.decomposition import PCA

# Load dataset
df = pd.read_csv("/content/Vibration_Dataset.csv")
# 2. Feature & target separation
X = df.iloc[:, :-8]
y = df.iloc[:, -8]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Extra Trees model
et_model = ExtraTreesClassifier(n_estimators=100, random_state=42)
et_model.fit(X_train, y_train)
et_preds = et_model.predict(X_test)

# 5. SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_train, y_train)

# 6. PCA
pca = PCA(n_components=0.95, random_state=42)
X_train_pca = pca.fit_transform(X_res)
X_test_pca = pca.transform(X_test)

# 7. Prepare for TFDF (TFDF expects DataFrame with string labels)
X_train_df = pd.DataFrame(X_train_pca, columns=[f'PC{i}' for i in range(X_train_pca.shape[1])])
X_train_df['label'] = y_res

X_test_df = pd.DataFrame(X_test_pca, columns=[f'PC{i}' for i in range(X_test_pca.shape[1])])
X_test_df['label'] = y_test.values

# 8. Convert to TF datasets
train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_train_df, label="label")
test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(X_test_df, label="label")

# 9. Train TFTB model
tf_model = tfdf.keras.GradientBoostedTreesModel()
tf_model.fit(train_ds)

# 10. Predict
y_pred_probs = tf_model.predict(test_ds)
y_pred_classes = np.argmax(y_pred_probs, axis=1)
class_labels = sorted(y.unique())
tf_pred = [class_labels[i] for i in y_pred_classes]

gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb_model.fit(X_train, y_train)
gb_preds = gb_model.predict(X_test)

# Ensemble (majority voting)
ensemble_preds = ((et_preds + gb_preds + tf_pred) > 1).astype(int)

# Metrics
accuracy = accuracy_score(y_test, ensemble_preds)
precision = precision_score(y_test, ensemble_preds)
recall = recall_score(y_test, ensemble_preds)
tn, fp, fn, tp = confusion_matrix(y_test, ensemble_preds).ravel()
specificity = tn / (tn + fp)

# Print metrics
print(f"Accuracy   : {accuracy:.4f}")
print(f"Precision  : {precision:.4f}")
print(f"Recall     : {recall:.4f}")
print(f"Specificity: {specificity:.4f}")

# Colorful confusion matrix
cm = confusion_matrix(y_test, ensemble_preds)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='YlGnBu',
            xticklabels=['No', 'Yes'],
            yticklabels=['No', 'Yes'])
plt.title('TensorFlow Extented Gradient Boosted Trees')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.tight_layout()
plt.show()